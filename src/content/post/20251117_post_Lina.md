---
publishDate: 2025-11-13T00:00:00Z
title: 'Write the Test First (Even for Your Science)'
slug: blog/quicktake/data-pipelines-that-scientists-can-debug-without-calling-you-at-9-pm
authors:
  - name: 'Lina L. Faller, Ph.D.'
    url: 'https://www.linkedin.com/in/linafaller/'
excerpt: 'Why data scientists should design error messages that guide users straight to solutions.'
image: '/blog_images/2025-11-17-write-the-test-first-even-for-your-science.png'
imageAlt: 'Side‚Äëby‚Äëside flowcharts comparing traditional vs. test‚Äëdriven development (TDD) approaches.'
imagePosition: top
category: Quick Take
tags:
  - bioinformatics
  - data-engineering
  - biotech
  - computational-biology
  - data-science

metadata:
  title: 'Write the Test First (Even for Your Science)'
  description: 'Why data scientists should design error messages that guide users straight to solutions.'
  canonical: https://raw.githubusercontent.com/lfaller/lfaller.github.io/refs/heads/main/_posts/2025-11-17-write-the-test-first-even-for-your-science.md
---

<details class="image-description">
<summary>Text description of flowcharts</summary>

The image shows two parallel workflows to finding bugs in code.

**Traditional approach**:

1. write complex script
2. run on 5,000 samples
3. get plausible results,
4. deploy to production
5. discover bug six months later.

**TDD approach**:

1. create 5 toy samples
2. write simplest version
3. catch bug immediately,
4. run on 500 samples
5. deploy to production with confidence.
</details>

"I spent three days debugging. Turned out I was normalizing AFTER filtering instead of before. Results looked plausible for weeks."

We've all been there.

Here's what software engineers figured out decades ago with Test-Driven Development (TDD): **Ask "How will I know if this is correct?" BEFORE you start coding.**

## The Scientific Version

Before you write that filtering script or ML model:

- Create a toy dataset where you know the answer (3 samples, obvious differences)
- Define what "correct" looks like
- Run your code
- If it fails on 3 samples, you caught your bug early
- If it passes, scale up with confidence

## Why This Matters

**Traditional:** Write custom script ‚Üí Run on real data ‚Üí Get plausible results ‚Üí Find bug 6 months later

**TDD:** Create toy example ‚Üí Build simplest version ‚Üí Catch bugs at 3 samples, not 300

## Real Example

Building a sample quality filtering script, I created synthetic data first: 10 samples where 3 should clearly fail, 7 should clearly pass.

Found my threshold logic was backwards immediately üêõ - when debugging meant 10 samples, not 10,000.

By the time I ran production data, I had confidence. Not hope. üéØ

## Start Tomorrow

Next time you write custom code:

- Make one toy dataset first
- Looking for upregulated genes? Make 3 genes go UP
- Filtering samples by quality? Make 2 pass, 1 fail
- Does your code do what you expect?

Yes = Trust it on real data

No = You just saved yourself from bad science

**The best time to catch bugs is when your dataset is small enough to debug by hand.**

What's your "found the bug too late" horror story?
